{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "blessed-arnold",
   "metadata": {},
   "source": [
    "# Project 7: Implement a scoring model.\n",
    "\n",
    "*Pierre-Eloi Ragetly*\n",
    "\n",
    "This project is part of the Data Scientist path proposed by OpenClassrooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "described-blind",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:55:30.111344Z",
     "start_time": "2022-01-07T09:55:28.910635Z"
    }
   },
   "outputs": [],
   "source": [
    "# File system management\n",
    "import os\n",
    "\n",
    "# Get execution time to compare models\n",
    "import time\n",
    "\n",
    "# Import numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams.update({'axes.edgecolor': 'white',\n",
    "                     'axes.facecolor': 'white',\n",
    "                     'axes.linewidth': 2.0,\n",
    "                     'figure.facecolor': 'white'})\n",
    "\n",
    "# Where to save the figures\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    folder_path = os.path.join(\"charts\")\n",
    "    if not os.path.isdir(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    path = os.path.join(\"charts\", fig_id + \".png\")\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-chair",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Prepare-the-data\" data-toc-modified-id=\"Prepare-the-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Prepare the data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Read-in-data\" data-toc-modified-id=\"Read-in-data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Read in data</a></span></li><li><span><a href=\"#Transform-data\" data-toc-modified-id=\"Transform-data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Transform data</a></span></li></ul></li><li><span><a href=\"#Shortlist-Promising-Models\" data-toc-modified-id=\"Shortlist-Promising-Models-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Shortlist Promising Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Select-a-Performance-Measure\" data-toc-modified-id=\"Select-a-Performance-Measure-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Select a Performance Measure</a></span></li><li><span><a href=\"#Establish-a-performance-baseline-with-a-dummy-classifier\" data-toc-modified-id=\"Establish-a-performance-baseline-with-a-dummy-classifier-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Establish a performance baseline with a dummy classifier</a></span></li><li><span><a href=\"#Train-quick-and-dirty-models-and-compare-their-performance\" data-toc-modified-id=\"Train-quick-and-dirty-models-and-compare-their-performance-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Train quick and dirty models and compare their performance</a></span></li><li><span><a href=\"#Data-augmentation-with-SMOTE\" data-toc-modified-id=\"Data-augmentation-with-SMOTE-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Data augmentation with SMOTE</a></span></li></ul></li><li><span><a href=\"#SMOTE-issue\" data-toc-modified-id=\"SMOTE-issue-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>SMOTE issue</a></span><ul class=\"toc-item\"><li><span><a href=\"#test-set-Creation\" data-toc-modified-id=\"test-set-Creation-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>test set Creation</a></span></li><li><span><a href=\"#Results-for-a-model-without-pipeline\" data-toc-modified-id=\"Results-for-a-model-without-pipeline-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Results for a model without pipeline</a></span></li><li><span><a href=\"#Results-for-a-model-with-a-pipeline\" data-toc-modified-id=\"Results-for-a-model-with-a-pipeline-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Results for a model with a pipeline</a></span></li></ul></li><li><span><a href=\"#Improve-the-promising-models\" data-toc-modified-id=\"Improve-the-promising-models-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Improve the promising models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Test-the-asumptions-made-for-data-cleaning.\" data-toc-modified-id=\"Test-the-asumptions-made-for-data-cleaning.-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Test the asumptions made for data cleaning.</a></span></li><li><span><a href=\"#Feature-Selection\" data-toc-modified-id=\"Feature-Selection-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Feature Selection</a></span></li></ul></li><li><span><a href=\"#Fine-Tune-the-hyperparameters\" data-toc-modified-id=\"Fine-Tune-the-hyperparameters-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Fine-Tune the hyperparameters</a></span><ul class=\"toc-item\"><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Random Forest</a></span></li><li><span><a href=\"#XGBoost\" data-toc-modified-id=\"XGBoost-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>XGBoost</a></span></li><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>LightGBM</a></span></li><li><span><a href=\"#Catboost\" data-toc-modified-id=\"Catboost-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Catboost</a></span></li><li><span><a href=\"#Compare-Results\" data-toc-modified-id=\"Compare-Results-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Compare Results</a></span></li><li><span><a href=\"#Best-model\" data-toc-modified-id=\"Best-model-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>Best model</a></span></li></ul></li><li><span><a href=\"#Analyse-feature-importance-with-SHAP\" data-toc-modified-id=\"Analyse-feature-importance-with-SHAP-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Analyse feature importance with SHAP</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-designation",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-metabolism",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incredible-imagination",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:56:02.218326Z",
     "start_time": "2022-01-07T09:55:31.466706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) application_test.csv\n",
      "2) application_train.csv\n",
      "3) bureau.csv\n",
      "4) bureau_balance.csv\n",
      "5) credit_card_balance.csv\n",
      "6) HomeCredit_columns_description.csv\n",
      "7) installments_payments.csv\n",
      "8) POS_CASH_balance.csv\n",
      "9) previous_application.csv\n",
      "10) sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "list_files = sorted(os.listdir(\"data/\"), key=str.lower)\n",
    "for i, file in enumerate(list_files):\n",
    "    print(\"{}) {}\".format(i+1, file))\n",
    "\n",
    "app_test = pd.read_csv(\"data/\" + list_files[0])\n",
    "app_train = pd.read_csv(\"data/\" + list_files[1])\n",
    "bureau =  pd.read_csv(\"data/\" + list_files[2])\n",
    "b_b = pd.read_csv(\"data/\" + list_files[3])\n",
    "cc_balance = pd.read_csv(\"data/\" + list_files[4])\n",
    "ins_payments = pd.read_csv(\"data/\" + list_files[6])\n",
    "pos_cash = pd.read_csv(\"data/\" + list_files[7])\n",
    "prev_app = pd.read_csv(\"data/\" + list_files[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-animation",
   "metadata": {},
   "source": [
    "### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "executed-recommendation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:56:02.313692Z",
     "start_time": "2022-01-07T09:56:02.220185Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from functions.preprocessing import drop_na_att\n",
    "from functions.preprocessing import impute_cat_att\n",
    "from functions.preprocessing import fix_sparse_anomalies\n",
    "from functions.preprocessing import fix_dense_anomalies\n",
    "from functions.preprocessing import add_domain_att\n",
    "from functions.preprocessing import tr_skew_att"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-guatemala",
   "metadata": {},
   "source": [
    "We will not use the following features for the modeling:\n",
    "- *SK_ID_CURR*\n",
    "- *EXT_SOURCE_1*\n",
    "- *EXT_SOURCE_2*\n",
    "- *EXT_SOURCE_3*\n",
    "\n",
    "The first one is an id, meaning it is unique for each client, and so does not bring any information and so has been dropped.\n",
    "For the three \"EXT_SOURCE\", it is totally different. The correlation study made previously suggests these features could be the major contributors of the final model. However, not knowing how these scores have been calculated, it would be impossible to us to explain a model based on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "unauthorized-subcommittee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:34:05.858094Z",
     "start_time": "2022-01-10T18:34:05.828296Z"
    }
   },
   "outputs": [],
   "source": [
    "test = X[cat_att]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "medieval-burke",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:36:00.714117Z",
     "start_time": "2022-01-10T18:36:00.239876Z"
    }
   },
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "test_tr = imputer.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "cardiovascular-smell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:52:39.281601Z",
     "start_time": "2022-01-10T18:52:39.062592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_CONTRACT_TYPE                               Cash loans\n",
       "CODE_GENDER                                               F\n",
       "FLAG_OWN_CAR                                              N\n",
       "FLAG_OWN_REALTY                                           Y\n",
       "NAME_TYPE_SUITE                               Unaccompanied\n",
       "NAME_INCOME_TYPE                                    Working\n",
       "NAME_EDUCATION_TYPE           Secondary / secondary special\n",
       "NAME_FAMILY_STATUS                                  Married\n",
       "NAME_HOUSING_TYPE                         House / apartment\n",
       "OCCUPATION_TYPE                                    Laborers\n",
       "WEEKDAY_APPR_PROCESS_START                          TUESDAY\n",
       "ORGANIZATION_TYPE                    Business Entity Type 3\n",
       "FONDKAPREMONT_MODE                         reg oper account\n",
       "HOUSETYPE_MODE                               block of flats\n",
       "WALLSMATERIAL_MODE                                    Panel\n",
       "EMERGENCYSTATE_MODE                                      No\n",
       "dtype: object"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([test[c].value_counts().index[0] for c in test],index=test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "frozen-berry",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T18:53:31.562722Z",
     "start_time": "2022-01-10T18:53:31.559578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cash loans', 'F', 'N', 'Y', 'Unaccompanied', 'Working',\n",
       "       'Secondary / secondary special', 'Married', 'House / apartment',\n",
       "       'Laborers', 'TUESDAY', 'Business Entity Type 3',\n",
       "       'reg oper account', 'block of flats', 'Panel', 'No'], dtype=object)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "adolescent-works",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T09:29:06.729432Z",
     "start_time": "2022-01-11T09:29:06.726896Z"
    }
   },
   "outputs": [],
   "source": [
    "arr = np.random.randn(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "banner-lodging",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T09:29:19.612344Z",
     "start_time": "2022-01-11T09:29:19.609091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "eligible-hunter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T09:29:38.146761Z",
     "start_time": "2022-01-11T09:29:38.143819Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "inappropriate-opposition",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T09:31:41.660272Z",
     "start_time": "2022-01-11T09:31:41.657195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "boxed-grenada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T09:39:09.504225Z",
     "start_time": "2022-01-11T09:39:09.502065Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "visible-crowd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T15:25:16.974318Z",
     "start_time": "2022-01-10T15:25:15.151716Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop the target and the ID of input data\n",
    "# as well as sourc \n",
    "X = app_train.drop(['SK_ID_CURR', 'EXT_SOURCE_1',\n",
    "                    'EXT_SOURCE_2', 'EXT_SOURCE_3','TARGET'], axis=1)\n",
    "\n",
    "# Get the categorical attributes\n",
    "cat_att = list(X.select_dtypes('object'))\n",
    "\n",
    "# Get the numerical attributes\n",
    "num_att = list(X.select_dtypes(['number']))\n",
    "ord_att = list(X[num_att].loc[:, X[num_att].nunique()<6])\n",
    "sparse_att = [c for c in num_att\n",
    "              if c not in ord_att\n",
    "              and (X[c]==0).sum() > 0.5*len(X)]\n",
    "dense_att = [c for c in num_att\n",
    "             if c not in ord_att\n",
    "             and c not in sparse_att]\n",
    "filtered_dense_att = list(drop_na_att(X[dense_att])) + ['DAYS_EMPLOYED_ANOM']\n",
    "\n",
    "# Create a pipeline with an encoder\n",
    "# drop the first category in each feature with two categories (drop='if_binary')\n",
    "cat_pipeline = Pipeline([\n",
    "               ('filter', FunctionTransformer(drop_na_att)),               \n",
    "               ('imputer', FunctionTransformer(impute_cat_att)),\n",
    "               ('encoder', OneHotEncoder(drop='if_binary'))\n",
    "               ])\n",
    "\n",
    "# Pipeline to prepare numerical ordinal features\n",
    "ord_pipeline = Pipeline([\n",
    "               ('filter', FunctionTransformer(drop_na_att)),\n",
    "               ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "               ])\n",
    "\n",
    "# Pipeline to prepare sparse features with at least 6 distinct values\n",
    "sparse_pipeline = Pipeline([\n",
    "                  ('filter', FunctionTransformer(drop_na_att)),\n",
    "                  ('cleaner', FunctionTransformer(fix_sparse_anomalies)),\n",
    "                  ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                  ('scaler', MaxAbsScaler())\n",
    "                  ])\n",
    "\n",
    "# Pipeline to prepare dense features with at least 6 distinct values\n",
    "dense_pipeline = Pipeline([\n",
    "                 ('filter', FunctionTransformer(drop_na_att)),\n",
    "                 ('cleaner', FunctionTransformer(fix_dense_anomalies)),\n",
    "                 ('imputer', SimpleImputer()),\n",
    "                 ('domain_adder', FunctionTransformer(add_domain_att,\n",
    "                                                      kw_args={'names': filtered_dense_att})),\n",
    "                 ('skew_transformer', FunctionTransformer(tr_skew_att)),\n",
    "                 ('scaler', StandardScaler())\n",
    "                 ])\n",
    "\n",
    "# Pipeline to prepare all data\n",
    "preparation = ColumnTransformer([\n",
    "              ('cat', cat_pipeline, cat_att),\n",
    "              ('ordinal', ord_pipeline, ord_att),\n",
    "              ('sparse', sparse_pipeline, sparse_att),\n",
    "              ('dense', dense_pipeline, dense_att)\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "resistant-vinyl",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T15:36:05.861591Z",
     "start_time": "2022-01-10T15:35:59.931690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 117)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_CONTRACT_TYPE_Revolving loans</th>\n",
       "      <th>CODE_GENDER_F</th>\n",
       "      <th>CODE_GENDER_M</th>\n",
       "      <th>CODE_GENDER_XNA</th>\n",
       "      <th>FLAG_OWN_CAR_Y</th>\n",
       "      <th>FLAG_OWN_REALTY_Y</th>\n",
       "      <th>NAME_TYPE_SUITE_Children</th>\n",
       "      <th>NAME_TYPE_SUITE_Family</th>\n",
       "      <th>NAME_TYPE_SUITE_Group of people</th>\n",
       "      <th>NAME_TYPE_SUITE_Other_A</th>\n",
       "      <th>...</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <th>DAYS_EMPLOYED_ANOM</th>\n",
       "      <th>DAYS_EMPLOYED_PERC</th>\n",
       "      <th>CREDIT_INCOME_PERC</th>\n",
       "      <th>INCOME_PER_PERSON</th>\n",
       "      <th>ANNUITY_INCOME_PERC</th>\n",
       "      <th>CREDIT_TERM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.265724</td>\n",
       "      <td>-0.631821</td>\n",
       "      <td>-0.206991</td>\n",
       "      <td>-5.176655e-01</td>\n",
       "      <td>-0.468635</td>\n",
       "      <td>-0.685451</td>\n",
       "      <td>-0.755852</td>\n",
       "      <td>1.548683</td>\n",
       "      <td>-0.629679</td>\n",
       "      <td>0.326909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167639</td>\n",
       "      <td>-0.325620</td>\n",
       "      <td>0.163108</td>\n",
       "      <td>-1.092866e+00</td>\n",
       "      <td>-0.468635</td>\n",
       "      <td>-0.652211</td>\n",
       "      <td>0.567970</td>\n",
       "      <td>0.912393</td>\n",
       "      <td>-0.510993</td>\n",
       "      <td>-1.178242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.265724</td>\n",
       "      <td>-0.938022</td>\n",
       "      <td>0.178831</td>\n",
       "      <td>-1.092866e+00</td>\n",
       "      <td>-0.468635</td>\n",
       "      <td>-1.222743</td>\n",
       "      <td>-0.761159</td>\n",
       "      <td>-0.175347</td>\n",
       "      <td>-0.888140</td>\n",
       "      <td>-0.155923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167639</td>\n",
       "      <td>1.511587</td>\n",
       "      <td>0.418307</td>\n",
       "      <td>-3.831603e-16</td>\n",
       "      <td>-0.468635</td>\n",
       "      <td>0.151233</td>\n",
       "      <td>-0.558658</td>\n",
       "      <td>-0.175347</td>\n",
       "      <td>0.463536</td>\n",
       "      <td>1.830833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.265724</td>\n",
       "      <td>-0.325620</td>\n",
       "      <td>-0.173126</td>\n",
       "      <td>-1.092866e+00</td>\n",
       "      <td>-0.468635</td>\n",
       "      <td>0.086094</td>\n",
       "      <td>0.359119</td>\n",
       "      <td>0.747053</td>\n",
       "      <td>0.028661</td>\n",
       "      <td>-0.490159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NAME_CONTRACT_TYPE_Revolving loans  CODE_GENDER_F  CODE_GENDER_M  \\\n",
       "0                                 0.0            0.0            1.0   \n",
       "1                                 0.0            1.0            0.0   \n",
       "2                                 1.0            0.0            1.0   \n",
       "3                                 0.0            1.0            0.0   \n",
       "4                                 0.0            0.0            1.0   \n",
       "\n",
       "   CODE_GENDER_XNA  FLAG_OWN_CAR_Y  FLAG_OWN_REALTY_Y  \\\n",
       "0              0.0             0.0                1.0   \n",
       "1              0.0             0.0                0.0   \n",
       "2              0.0             1.0                1.0   \n",
       "3              0.0             0.0                1.0   \n",
       "4              0.0             0.0                1.0   \n",
       "\n",
       "   NAME_TYPE_SUITE_Children  NAME_TYPE_SUITE_Family  \\\n",
       "0                       0.0                     0.0   \n",
       "1                       0.0                     1.0   \n",
       "2                       0.0                     0.0   \n",
       "3                       0.0                     0.0   \n",
       "4                       0.0                     0.0   \n",
       "\n",
       "   NAME_TYPE_SUITE_Group of people  NAME_TYPE_SUITE_Other_A  ...  \\\n",
       "0                              0.0                      0.0  ...   \n",
       "1                              0.0                      0.0  ...   \n",
       "2                              0.0                      0.0  ...   \n",
       "3                              0.0                      0.0  ...   \n",
       "4                              0.0                      0.0  ...   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                   -1.265724                  -0.631821   \n",
       "1                   -0.167639                  -0.325620   \n",
       "2                   -1.265724                  -0.938022   \n",
       "3                   -0.167639                   1.511587   \n",
       "4                   -1.265724                  -0.325620   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  DAYS_EMPLOYED_ANOM  \\\n",
       "0                  -0.206991               -5.176655e-01           -0.468635   \n",
       "1                   0.163108               -1.092866e+00           -0.468635   \n",
       "2                   0.178831               -1.092866e+00           -0.468635   \n",
       "3                   0.418307               -3.831603e-16           -0.468635   \n",
       "4                  -0.173126               -1.092866e+00           -0.468635   \n",
       "\n",
       "   DAYS_EMPLOYED_PERC  CREDIT_INCOME_PERC  INCOME_PER_PERSON  \\\n",
       "0           -0.685451           -0.755852           1.548683   \n",
       "1           -0.652211            0.567970           0.912393   \n",
       "2           -1.222743           -0.761159          -0.175347   \n",
       "3            0.151233           -0.558658          -0.175347   \n",
       "4            0.086094            0.359119           0.747053   \n",
       "\n",
       "   ANNUITY_INCOME_PERC  CREDIT_TERM  \n",
       "0            -0.629679     0.326909  \n",
       "1            -0.510993    -1.178242  \n",
       "2            -0.888140    -0.155923  \n",
       "3             0.463536     1.830833  \n",
       "4             0.028661    -0.490159  \n",
       "\n",
       "[5 rows x 166 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data\n",
    "y_train = app_train['TARGET']\n",
    "X_train = preparation.fit_transform(X)\n",
    "print(X.shape)\n",
    "# Get the name of onehot encoded features\n",
    "onehot_att = list(drop_na_att(X[cat_att]))\n",
    "encoder = OneHotEncoder(drop='if_binary')\n",
    "encoder.fit(impute_cat_att(X[onehot_att]))\n",
    "onehot_att = list(encoder.get_feature_names(onehot_att))\n",
    "# Get the name of domain attributes\n",
    "domain_att = ['DAYS_EMPLOYED_PERC', 'CREDIT_INCOME_PERC', 'INCOME_PER_PERSON',\n",
    "              'ANNUITY_INCOME_PERC', 'CREDIT_TERM']\n",
    "# Get the name of all attributes\n",
    "extra_att = ['DAYS_EMPLOYED_ANOM'] + domain_att\n",
    "att = onehot_att + list(drop_na_att(X[num_att])) + extra_att\n",
    "\n",
    "df_train = pd.DataFrame(X_train, columns=att)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-international",
   "metadata": {},
   "source": [
    "## Shortlist Promising Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-sailing",
   "metadata": {},
   "source": [
    "### Select a Performance Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "extended-basket",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:56:07.742191Z",
     "start_time": "2022-01-07T09:56:07.738278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of the positive class: 8.1%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percentage of the positive class: \\\n",
    "{app_train['TARGET'].value_counts()[1]/len(app_train):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-rating",
   "metadata": {},
   "source": [
    "Though *accuracy* is generally the first performance used for binary classification, it is seldom the best choice when we are dealing with *skewed dataset*, like the one we have.  \n",
    "To prove it, let's take a very dumb classifier that just classifies every instance in the *negative* class (meaning the majority class). We would get an accuracy of $92\\%$, not bad for such dumb classifier! Thus, no matter the model used, the accuracy will be high. It will be difficult to know if our model really learn something, whether it has skill on the dataset.\n",
    "\n",
    "There are much better way to evaluate the performance of a classifier, all depends on the model's objective. Let's remind ourselves the objective: **predict whether a new client will be in default or not.** It will cost much more money for the bank to grant a loan to a person that will be not able to repay it, than the opposite, refuse to approve a loan for someone who could pay it back. Meaning we care more about *False Negative* than *False Positive*, in other words, whe prefer having a high *Recall* than a high *Precision*.\n",
    "\n",
    "The $F_1$ score is often used for imbalanced data and binary classification problems. It is the *harmonic mean* of *Precision* and *Recall*:\n",
    "\n",
    "$\\displaystyle F_1 = 2 \\times \\frac {precision \\times recall}{precision + recall}$\n",
    "\n",
    "The $F_1$ score favors classifiers that have similar *precision* and *recall*. As said above, this is not what we want. Then, we will use another score typically used for such problem: the *AUC* score. AUC standing for \"Area Under the Curve\". Two curves can be used to compute the AUC:\n",
    "- the Precision-Recall (PR) curve\n",
    "- the Receiver Operating Characteristic (ROC) curve\n",
    "\n",
    "The former is prefered when:\n",
    "- the positive class is rare or,\n",
    "- you care more about the false positives than the false negative.\n",
    "\n",
    "Here, we definitely care more about the false negatives than false postives, but the dataset is severely imbalanced with the positive class as the minority one. So we should use the PR curve. However, as we will see in the next section, we will use a technique named SMOTE (Synthetic Minority Oversampling Technique) to oversample the minority class, and as we are more concern by the recall than the precision, **we will compute the ROC AUC.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-diversity",
   "metadata": {},
   "source": [
    "### Establish a performance baseline with a dummy classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-advocacy",
   "metadata": {},
   "source": [
    "A performance baseline provides a minimum score above which a model is considered to have skill on the dataset. It provides a line by which all other algorithms can be compared. A baseline can be established using a naive classifier, such as predicting the most frequent class label for all examples in the dataset.\n",
    "\n",
    "Each metric requires the careful choice of a specific naive classification strategy that achieves the appropriate \"*no skill*\" performance. A no-skill model has a ROC AUC of 0.5 and can be achieved by predicting class labels randomly, while respecting the training set's class distribution (e.g. 8.1% for the positive class).  \n",
    "We will use the \"*stratified*\" strategy of the sklearn class `DummyClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "athletic-external",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T09:56:08.638083Z",
     "start_time": "2022-01-07T09:56:07.743581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC for the dummy classifier: 0.50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Train a dummy classifier\n",
    "dummy_clf = DummyClassifier(strategy='stratified')\n",
    "\n",
    "# Get the ROC AUC\n",
    "cv = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "dummy_scores = cross_val_score(dummy_clf, X_train, y_train,\n",
    "                               scoring='roc_auc', cv=cv, n_jobs=1)\n",
    "print(f\"ROC AUC for the dummy classifier: {dummy_scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-barbados",
   "metadata": {},
   "source": [
    "### Train quick and dirty models and compare their performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "oriental-sleeve",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T10:02:19.757197Z",
     "start_time": "2022-01-07T09:56:08.639488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit time (s)</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CatBoost Classifier</th>\n",
       "      <td>95.550789</td>\n",
       "      <td>0.919125</td>\n",
       "      <td>0.419129</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>0.009715</td>\n",
       "      <td>0.715462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM Classifier</th>\n",
       "      <td>6.309871</td>\n",
       "      <td>0.919261</td>\n",
       "      <td>0.475238</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.713636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost Classifier</th>\n",
       "      <td>153.455286</td>\n",
       "      <td>0.919063</td>\n",
       "      <td>0.418265</td>\n",
       "      <td>0.007009</td>\n",
       "      <td>0.013785</td>\n",
       "      <td>0.710244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>2.281053</td>\n",
       "      <td>0.919271</td>\n",
       "      <td>0.560317</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.679286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>75.560856</td>\n",
       "      <td>0.919291</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.657029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM - Linear kernel</th>\n",
       "      <td>2.633609</td>\n",
       "      <td>0.919271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>1.539795</td>\n",
       "      <td>0.132038</td>\n",
       "      <td>0.082575</td>\n",
       "      <td>0.964512</td>\n",
       "      <td>0.152126</td>\n",
       "      <td>0.556988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>16.639357</td>\n",
       "      <td>0.848087</td>\n",
       "      <td>0.119532</td>\n",
       "      <td>0.138570</td>\n",
       "      <td>0.128346</td>\n",
       "      <td>0.524483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          fit time (s)  Accuracy  Precision    Recall  \\\n",
       "CatBoost Classifier          95.550789  0.919125   0.419129  0.004914   \n",
       "LightGBM Classifier           6.309871  0.919261   0.475238  0.001208   \n",
       "XGBoost Classifier          153.455286  0.919063   0.418265  0.007009   \n",
       "Logistic Regression           2.281053  0.919271   0.560317  0.001047   \n",
       "Random Forest Classifier     75.560856  0.919291   0.800000  0.000242   \n",
       "SVM - Linear kernel           2.633609  0.919271   0.000000  0.000000   \n",
       "Gaussian Naive Bayes          1.539795  0.132038   0.082575  0.964512   \n",
       "Decision Tree Classifier     16.639357  0.848087   0.119532  0.138570   \n",
       "\n",
       "                          F1 Score   ROC AUC  \n",
       "CatBoost Classifier       0.009715  0.715462  \n",
       "LightGBM Classifier       0.002410  0.713636  \n",
       "XGBoost Classifier        0.013785  0.710244  \n",
       "Logistic Regression       0.002088  0.679286  \n",
       "Random Forest Classifier  0.000483  0.657029  \n",
       "SVM - Linear kernel       0.000000  0.597747  \n",
       "Gaussian Naive Bayes      0.152126  0.556988  \n",
       "Decision Tree Classifier  0.128346  0.524483  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functions.modeling import compare_models\n",
    "\n",
    "compare_models(X_train, y_train, sort='ROC AUC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-springer",
   "metadata": {},
   "source": [
    "### Data augmentation with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "verified-facial",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T10:33:28.079146Z",
     "start_time": "2022-01-07T10:33:17.862196Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_smote, y_smote = SMOTE(random_state=42).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "united-newton",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T10:33:28.083883Z",
     "start_time": "2022-01-07T10:33:28.080817Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 166)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "comparative-hindu",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T10:33:28.090042Z",
     "start_time": "2022-01-07T10:33:28.086245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(565372, 166)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_smote.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "trying-independence",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T10:17:34.850214Z",
     "start_time": "2022-01-07T10:02:29.599420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit time (s)</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>166.687467</td>\n",
       "      <td>0.957697</td>\n",
       "      <td>0.999780</td>\n",
       "      <td>0.915595</td>\n",
       "      <td>0.955837</td>\n",
       "      <td>0.987129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost Classifier</th>\n",
       "      <td>295.749504</td>\n",
       "      <td>0.955449</td>\n",
       "      <td>0.999170</td>\n",
       "      <td>0.911655</td>\n",
       "      <td>0.953408</td>\n",
       "      <td>0.974777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost Classifier</th>\n",
       "      <td>360.147786</td>\n",
       "      <td>0.955539</td>\n",
       "      <td>0.999349</td>\n",
       "      <td>0.911672</td>\n",
       "      <td>0.953499</td>\n",
       "      <td>0.974496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM Classifier</th>\n",
       "      <td>17.337592</td>\n",
       "      <td>0.955203</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.910501</td>\n",
       "      <td>0.953107</td>\n",
       "      <td>0.974194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>24.661468</td>\n",
       "      <td>0.911437</td>\n",
       "      <td>0.904345</td>\n",
       "      <td>0.920208</td>\n",
       "      <td>0.912207</td>\n",
       "      <td>0.911437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM - Linear kernel</th>\n",
       "      <td>5.659001</td>\n",
       "      <td>0.659017</td>\n",
       "      <td>0.651134</td>\n",
       "      <td>0.688506</td>\n",
       "      <td>0.668119</td>\n",
       "      <td>0.716906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>4.363592</td>\n",
       "      <td>0.657740</td>\n",
       "      <td>0.653812</td>\n",
       "      <td>0.679421</td>\n",
       "      <td>0.663951</td>\n",
       "      <td>0.716781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>2.667754</td>\n",
       "      <td>0.539894</td>\n",
       "      <td>0.522067</td>\n",
       "      <td>0.943842</td>\n",
       "      <td>0.672277</td>\n",
       "      <td>0.553358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          fit time (s)  Accuracy  Precision    Recall  \\\n",
       "Random Forest Classifier    166.687467  0.957697   0.999780  0.915595   \n",
       "CatBoost Classifier         295.749504  0.955449   0.999170  0.911655   \n",
       "XGBoost Classifier          360.147786  0.955539   0.999349  0.911672   \n",
       "LightGBM Classifier          17.337592  0.955203   0.999895  0.910501   \n",
       "Decision Tree Classifier     24.661468  0.911437   0.904345  0.920208   \n",
       "SVM - Linear kernel           5.659001  0.659017   0.651134  0.688506   \n",
       "Logistic Regression           4.363592  0.657740   0.653812  0.679421   \n",
       "Gaussian Naive Bayes          2.667754  0.539894   0.522067  0.943842   \n",
       "\n",
       "                          F1 Score   ROC AUC  \n",
       "Random Forest Classifier  0.955837  0.987129  \n",
       "CatBoost Classifier       0.953408  0.974777  \n",
       "XGBoost Classifier        0.953499  0.974496  \n",
       "LightGBM Classifier       0.953107  0.974194  \n",
       "Decision Tree Classifier  0.912207  0.911437  \n",
       "SVM - Linear kernel       0.668119  0.716906  \n",
       "Logistic Regression       0.663951  0.716781  \n",
       "Gaussian Naive Bayes      0.672277  0.553358  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models(X_smote, y_smote, sort='ROC AUC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-dylan",
   "metadata": {},
   "source": [
    "We will continue with:\n",
    "- Random Forest\n",
    "- CatBoost\n",
    "- Light GBM\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-import",
   "metadata": {},
   "source": [
    "## SMOTE issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-hampshire",
   "metadata": {},
   "source": [
    "### test set Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-joshua",
   "metadata": {},
   "source": [
    "Let's create 2 dataset:\n",
    "* one balanced\n",
    "* one imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "dedicated-audio",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T16:55:24.358212Z",
     "start_time": "2022-01-10T16:55:24.211932Z"
    }
   },
   "outputs": [],
   "source": [
    "X = app_train.drop(['SK_ID_CURR', 'EXT_SOURCE_1',\n",
    "                    'EXT_SOURCE_2', 'EXT_SOURCE_3','TARGET'], axis=1)\n",
    "y_train = app_train['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "headed-payroll",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T16:58:27.864372Z",
     "start_time": "2022-01-10T16:58:27.858359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    282686\n",
      "1     24825\n",
      "Name: TARGET, dtype: int64\n",
      "minority classe 8.07%\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())\n",
    "min_perc = y_train.value_counts()[1] / len(y_train)\n",
    "print(f'minority classe {min_perc:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "fluid-local",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T16:58:29.483242Z",
     "start_time": "2022-01-10T16:58:29.306407Z"
    }
   },
   "outputs": [],
   "source": [
    "idx_0 = X[y_train == 0].index.to_list()\n",
    "idx_1 = X[y_train == 1].index.to_list()\n",
    "# Get the index to create the test set\n",
    "idx_imbal = idx_0[:9200] + idx_1[:800]\n",
    "idx_bal = idx_0[:5000] + idx_1[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "centered-solid",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T16:58:30.498156Z",
     "start_time": "2022-01-10T16:58:30.490155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 117)\n"
     ]
    }
   ],
   "source": [
    "# Create the imbalanced test set\n",
    "X_test_imbal = X.loc[idx_imbal]\n",
    "y_test_imbal = y_train.loc[idx_imbal]\n",
    "print(X_test_imbal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "geographic-czech",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T16:58:31.669909Z",
     "start_time": "2022-01-10T16:58:31.658175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 117)\n"
     ]
    }
   ],
   "source": [
    "# Create the balanced test set\n",
    "X_test_bal = X.loc[idx_bal]\n",
    "y_test_bal = y_train.loc[idx_bal]\n",
    "print(X_test_bal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-james",
   "metadata": {},
   "source": [
    "### Results for a model without pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "multiple-preparation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T17:06:45.549454Z",
     "start_time": "2022-01-10T17:06:44.841878Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the categorical attributes\n",
    "cat_att = list(X.select_dtypes('object'))\n",
    "\n",
    "# Get the numerical attributes\n",
    "num_att = list(X.select_dtypes(['number']))\n",
    "ord_att = list(X[num_att].loc[:, X[num_att].nunique()<6])\n",
    "sparse_att = [c for c in num_att\n",
    "              if c not in ord_att\n",
    "              and (X[c]==0).sum() > 0.5*len(X)]\n",
    "dense_att = [c for c in num_att\n",
    "             if c not in ord_att\n",
    "             and c not in sparse_att]\n",
    "filtered_dense_att = list(X[dense_att]) + ['DAYS_EMPLOYED_ANOM']\n",
    "#filtered_dense_att = list(drop_na_att(X[dense_att])) + ['DAYS_EMPLOYED_ANOM']\n",
    "\n",
    "# Create a pipeline with an encoder\n",
    "# drop the first category in each feature with two categories (drop='if_binary')\n",
    "cat_pipeline = Pipeline([\n",
    "               #('filter', FunctionTransformer(drop_na_att)),               \n",
    "               ('imputer', FunctionTransformer(impute_cat_att)),\n",
    "               #('encoder', OneHotEncoder(drop='if_binary'))\n",
    "               ])\n",
    "\n",
    "# Pipeline to prepare numerical ordinal features\n",
    "ord_pipeline = Pipeline([\n",
    "               #('filter', FunctionTransformer(drop_na_att)),\n",
    "               ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "               ])\n",
    "\n",
    "# Pipeline to prepare sparse features with at least 6 distinct values\n",
    "sparse_pipeline = Pipeline([\n",
    "                  #('filter', FunctionTransformer(drop_na_att)),\n",
    "                  ('cleaner', FunctionTransformer(fix_sparse_anomalies)),\n",
    "                  ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                  ('scaler', MaxAbsScaler())\n",
    "                  ])\n",
    "\n",
    "# Pipeline to prepare dense features with at least 6 distinct values\n",
    "dense_pipeline = Pipeline([\n",
    "                 #('filter', FunctionTransformer(drop_na_att)),\n",
    "                 ('cleaner', FunctionTransformer(fix_dense_anomalies)),\n",
    "                 ('imputer', SimpleImputer()),\n",
    "                 ('domain_adder', FunctionTransformer(add_domain_att,\n",
    "                                                      kw_args={'names': filtered_dense_att})),\n",
    "                 ('skew_transformer', FunctionTransformer(tr_skew_att)),\n",
    "                 ('scaler', StandardScaler())\n",
    "                 ])\n",
    "\n",
    "# Pipeline to prepare all data\n",
    "preparation = ColumnTransformer([\n",
    "              #('cat', cat_pipeline, cat_att),\n",
    "              ('ordinal', ord_pipeline, ord_att),\n",
    "              ('sparse', sparse_pipeline, sparse_att),\n",
    "              ('dense', dense_pipeline, dense_att)\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "suffering-plenty",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T17:06:52.763051Z",
     "start_time": "2022-01-10T17:06:47.536751Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X_pr = preparation.fit_transform(X)\n",
    "X_test_bal_pr = preparation.transform(X_test_bal)\n",
    "X_test_imbal_pr = preparation.transform(X_test_imbal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "smoking-assets",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T17:06:56.638763Z",
     "start_time": "2022-01-10T17:06:53.352616Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a model without SMOTE\n",
    "model_no_smote = LGBMClassifier(n_estimators=100,\n",
    "                                random_state=42)\n",
    "model_no_smote.fit(X_pr, y_train)\n",
    "y_bal_pred = model_no_smote.predict(X_test_bal_pr)\n",
    "y_imbal_pred = model_no_smote.predict(X_test_imbal_pr)\n",
    "y_bal_prob = model_no_smote.predict_proba(X_test_bal_pr)[:, 1]\n",
    "y_imbal_prob = model_no_smote.predict_proba(X_test_imbal_pr)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "rubber-drilling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T17:06:56.644178Z",
     "start_time": "2022-01-10T17:06:56.640594Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def get_scores(y_true, y_pred, y_pred_prob):\n",
    "    scores = []\n",
    "    scores.append(accuracy_score(y_true, y_pred))\n",
    "    scores.append(precision_score(y_true, y_pred))\n",
    "    scores.append(recall_score(y_true, y_pred))\n",
    "    scores.append(f1_score(y_true, y_pred))\n",
    "    scores.append(roc_auc_score(y_true, y_pred_prob))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "treated-excess",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T17:06:57.900658Z",
     "start_time": "2022-01-10T17:06:57.881012Z"
    }
   },
   "outputs": [],
   "source": [
    "bal_scores_no_smote = get_scores(y_test_bal, y_bal_pred, y_bal_prob)\n",
    "imbal_scores_no_smote = get_scores(y_test_imbal, y_imbal_pred, y_imbal_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-bishop",
   "metadata": {},
   "source": [
    "Let's try with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "suited-chicken",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T17:07:16.967623Z",
     "start_time": "2022-01-10T17:07:00.289112Z"
    }
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "X_smote, y_smote = SMOTE(random_state=42).fit_resample(X_pr, y_train)\n",
    "model_smote = LGBMClassifier(n_estimators=100,\n",
    "                             random_state=42)\n",
    "model_smote.fit(X_smote, y_smote)\n",
    "# Get prediction\n",
    "y_bal_pred = model_smote.predict(X_test_bal_pr)\n",
    "y_imbal_pred = model_smote.predict(X_test_imbal_pr)\n",
    "y_bal_prob = model_smote.predict_proba(X_test_bal_pr)[:, 1]\n",
    "y_imbal_prob = model_smote.predict_proba(X_test_imbal_pr)[:, 1]\n",
    "# Get scores\n",
    "bal_scores_smote = get_scores(y_test_bal, y_bal_pred, y_bal_prob)\n",
    "imbal_scores_smote = get_scores(y_test_imbal, y_imbal_pred, y_imbal_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-accounting",
   "metadata": {},
   "source": [
    "### Results for a model with a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "second-rainbow",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T17:07:25.133785Z",
     "start_time": "2022-01-10T17:07:16.969181Z"
    }
   },
   "outputs": [],
   "source": [
    "import imblearn.pipeline as imbpipe\n",
    "\n",
    "# train a pipeline model without smote\n",
    "pipe_no_smote = imbpipe.Pipeline([\n",
    "                ('cleaning', preparation),\n",
    "                ('model', lgbm)\n",
    "                ])\n",
    "pipe_no_smote.fit(X, y_train)\n",
    "# Get prediction\n",
    "y_bal_pred = pipe_no_smote.predict(X_test_bal)\n",
    "y_imbal_pred = pipe_no_smote.predict(X_test_imbal)\n",
    "y_bal_prob = pipe_no_smote.predict_proba(X_test_bal)[:, 1]\n",
    "y_imbal_prob = pipe_no_smote.predict_proba(X_test_imbal)[:, 1]\n",
    "# Get scores\n",
    "bal_scores_pipe = get_scores(y_test_bal, y_bal_pred, y_bal_prob)\n",
    "imbal_scores_pipe = get_scores(y_test_imbal, y_imbal_pred, y_imbal_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "operational-teddy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T17:07:45.678119Z",
     "start_time": "2022-01-10T17:07:25.135727Z"
    }
   },
   "outputs": [],
   "source": [
    "# train a pipeline model with smote\n",
    "pipe_smote = imbpipe.Pipeline([\n",
    "             ('cleaning', preparation),\n",
    "             ('over', SMOTE(n_jobs=1, random_state=42)),\n",
    "             ('model', lgbm)\n",
    "             ])\n",
    "pipe_smote.fit(X, y_train)\n",
    "# Get prediction\n",
    "y_bal_pred = pipe_smote.predict(X_test_bal)\n",
    "y_imbal_pred = pipe_smote.predict(X_test_imbal)\n",
    "y_bal_prob = pipe_smote.predict_proba(X_test_bal)[:, 1]\n",
    "y_imbal_prob = pipe_smote.predict_proba(X_test_imbal)[:, 1]\n",
    "# Get scores\n",
    "bal_scores_pipe_smote = get_scores(y_test_bal, y_bal_pred, y_bal_prob)\n",
    "imbal_scores_pipe_smote = get_scores(y_test_imbal, y_imbal_pred, y_imbal_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "prompt-annex",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T17:07:45.688302Z",
     "start_time": "2022-01-10T17:07:45.679607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Balanced</th>\n",
       "      <td>0.5004</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.757741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Imbalanced</th>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.782552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced_SMOTE</th>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.707429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Imbalanced_SMOTE</th>\n",
       "      <td>0.9198</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.727598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced_pipe</th>\n",
       "      <td>0.5004</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.757741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Imbalanced_pipe</th>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.782552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced_pipe_SMOTE</th>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.707429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Imbalanced_pipe_SMOTE</th>\n",
       "      <td>0.9198</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.727598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Accuracy  Precision  Recall  F1 Score   ROC AUC\n",
       "Balanced                 0.5004       1.00  0.0008  0.001599  0.757741\n",
       "Imbalanced               0.9200       0.00  0.0000  0.000000  0.782552\n",
       "Balanced_SMOTE           0.5004       0.75  0.0012  0.002396  0.707429\n",
       "Imbalanced_SMOTE         0.9198       0.00  0.0000  0.000000  0.727598\n",
       "Balanced_pipe            0.5004       1.00  0.0008  0.001599  0.757741\n",
       "Imbalanced_pipe          0.9200       0.00  0.0000  0.000000  0.782552\n",
       "Balanced_pipe_SMOTE      0.5004       0.75  0.0012  0.002396  0.707429\n",
       "Imbalanced_pipe_SMOTE    0.9198       0.00  0.0000  0.000000  0.727598"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the scores in a DataFrame\n",
    "columns = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']\n",
    "index = ['Balanced', 'Imbalanced',\n",
    "         'Balanced_SMOTE', 'Imbalanced_SMOTE',\n",
    "         'Balanced_pipe', 'Imbalanced_pipe',\n",
    "         'Balanced_pipe_SMOTE', 'Imbalanced_pipe_SMOTE']\n",
    "scores = np.array([bal_scores_no_smote, imbal_scores_no_smote,\n",
    "                   bal_scores_smote, imbal_scores_smote,\n",
    "                   bal_scores_pipe, imbal_scores_pipe,\n",
    "                   bal_scores_pipe_smote, imbal_scores_pipe_smote])\n",
    "pd.DataFrame(scores, columns=columns, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-shanghai",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "distant-cycling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T14:02:00.943947Z",
     "start_time": "2022-01-10T14:01:48.835853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit time (s)</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>CV ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no_smote_no_pipe</th>\n",
       "      <td>1.310657</td>\n",
       "      <td>0.755679</td>\n",
       "      <td>0.713937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fit time (s)   ROC AUC  CV ROC AUC\n",
       "no_smote_no_pipe      1.310657  0.755679    0.713937"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "cv = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "lgbm = LGBMClassifier(n_estimators=100,\n",
    "                      random_state=42)\n",
    "\n",
    "t0 = time.time()\n",
    "lgbm.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "y_pred = lgbm.predict_proba(X_train)\n",
    "y_pred_cv = cross_val_predict(lgbm, X_train, y_train, cv=cv, n_jobs=-1,\n",
    "                              method=\"predict_proba\")\n",
    "\n",
    "time_fit = t1 - t0\n",
    "score = roc_auc_score(y_train, y_pred[:, 1])\n",
    "cv_score = roc_auc_score(y_train, y_pred_cv[:, 1])\n",
    "\n",
    "pd.DataFrame(np.array([time_fit, score, cv_score]).reshape(1, -1),\n",
    "             columns=['fit time (s)', 'ROC AUC', 'CV ROC AUC'],\n",
    "             index=[\"no_smote_no_pipe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "crucial-sterling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T14:02:03.232459Z",
     "start_time": "2022-01-07T14:01:42.265452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit time (s)</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>CV ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no_smote_imblearn_pipe</th>\n",
       "      <td>5.55989</td>\n",
       "      <td>0.755679</td>\n",
       "      <td>0.714048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        fit time (s)   ROC AUC  CV ROC AUC\n",
       "no_smote_imblearn_pipe       5.55989  0.755679    0.714048"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imblearn.pipeline as imbpipe\n",
    "\n",
    "imb_pipe = imbpipe.Pipeline([\n",
    "           ('cleaning', full_pipeline),\n",
    "           ('model', lgbm)\n",
    "           ])\n",
    "\n",
    "t0 = time.time()\n",
    "imb_pipe.fit(X, y_train)\n",
    "t1 = time.time()\n",
    "y_pred = imb_pipe.predict_proba(X)\n",
    "y_pred_cv = cross_val_predict(imb_pipe, X, y_train, cv=cv, n_jobs=-1,\n",
    "                              method=\"predict_proba\")\n",
    "\n",
    "time_fit = t1 - t0\n",
    "score = roc_auc_score(y_train, y_pred[:, 1])\n",
    "cv_score = roc_auc_score(y_train, y_pred_cv[:, 1])\n",
    "\n",
    "pd.DataFrame(np.array([time_fit, score, cv_score]).reshape(1, -1),\n",
    "             columns=['fit time (s)', 'ROC AUC', 'CV ROC AUC'],\n",
    "             index=[\"no_smote_imblearn_pipe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "controlling-thirty",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T14:03:14.861351Z",
     "start_time": "2022-01-07T14:02:54.956703Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit time (s)</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>CV ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no_smote_sklearn_pipe</th>\n",
       "      <td>4.902412</td>\n",
       "      <td>0.755679</td>\n",
       "      <td>0.714048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       fit time (s)   ROC AUC  CV ROC AUC\n",
       "no_smote_sklearn_pipe      4.902412  0.755679    0.714048"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "sk_pipe = Pipeline([\n",
    "          ('cleaning', full_pipeline),\n",
    "          ('model', lgbm)\n",
    "          ])\n",
    "\n",
    "t0 = time.time()\n",
    "sk_pipe.fit(X, y_train)\n",
    "t1 = time.time()\n",
    "y_pred = sk_pipe.predict_proba(X)\n",
    "y_pred_cv = cross_val_predict(sk_pipe, X, y_train, cv=cv, n_jobs=-1,\n",
    "                              method=\"predict_proba\")\n",
    "\n",
    "time_fit = t1 - t0\n",
    "score = roc_auc_score(y_train, y_pred[:, 1])\n",
    "cv_score = roc_auc_score(y_train, y_pred_cv[:, 1])\n",
    "\n",
    "pd.DataFrame(np.array([time_fit, score, cv_score]).reshape(1, -1),\n",
    "             columns=['fit time (s)', 'ROC AUC', 'CV ROC AUC'],\n",
    "             index=[\"no_smote_sklearn_pipe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "valued-differential",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T14:05:21.951456Z",
     "start_time": "2022-01-07T14:04:51.059729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit time (s)</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>CV ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smote_no_pipe</th>\n",
       "      <td>4.298799</td>\n",
       "      <td>0.720385</td>\n",
       "      <td>0.974202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               fit time (s)   ROC AUC  CV ROC AUC\n",
       "smote_no_pipe      4.298799  0.720385    0.974202"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_smote, y_smote = SMOTE(random_state=42).fit_resample(X_train, y_train)\n",
    "\n",
    "t0 = time.time()\n",
    "lgbm.fit(X_smote, y_smote)\n",
    "t1 = time.time()\n",
    "y_pred = lgbm.predict_proba(X_train)\n",
    "y_pred_cv = cross_val_predict(lgbm, X_smote, y_smote, cv=cv, n_jobs=-1,\n",
    "                              method=\"predict_proba\")\n",
    "\n",
    "time_fit = t1 - t0\n",
    "score = roc_auc_score(y_train, y_pred[:, 1])\n",
    "cv_score = roc_auc_score(y_smote, y_pred_cv[:, 1])\n",
    "\n",
    "pd.DataFrame(np.array([time_fit, score, cv_score]).reshape(1, -1),\n",
    "             columns=['fit time (s)', 'ROC AUC', 'CV ROC AUC'],\n",
    "             index=[\"smote_no_pipe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "elementary-pattern",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T14:06:20.489676Z",
     "start_time": "2022-01-07T14:05:25.562677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit time (s)</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>CV ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smote_imblearn_pipe</th>\n",
       "      <td>16.430366</td>\n",
       "      <td>0.720385</td>\n",
       "      <td>0.703612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fit time (s)   ROC AUC  CV ROC AUC\n",
       "smote_imblearn_pipe     16.430366  0.720385    0.703612"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imb_pipe = imbpipe.Pipeline([\n",
    "           ('cleaning', full_pipeline),\n",
    "           ('over', SMOTE(n_jobs=1, random_state=42)),\n",
    "           ('model', lgbm)\n",
    "           ])\n",
    "\n",
    "t0 = time.time()\n",
    "imb_pipe.fit(X, y_train)\n",
    "t1 = time.time()\n",
    "y_pred = imb_pipe.predict_proba(X)\n",
    "y_pred_cv = cross_val_predict(imb_pipe, X, y_train, cv=cv, n_jobs=-1,\n",
    "                              method=\"predict_proba\")\n",
    "\n",
    "time_fit = t1 - t0\n",
    "score = roc_auc_score(y_train, y_pred[:, 1])\n",
    "cv_score = roc_auc_score(y_train, y_pred_cv[:, 1])\n",
    "\n",
    "pd.DataFrame(np.array([time_fit, score, cv_score.mean()]).reshape(1, -1),\n",
    "             columns=['fit time (s)', 'ROC AUC', 'CV ROC AUC'],\n",
    "\n",
    "             index=[\"smote_imblearn_pipe\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-apple",
   "metadata": {},
   "source": [
    "Surprisingly, results are better without oversampling.\n",
    "\n",
    "In the SMOTE paper, it is mentionned that SMOTE performs better when combined with undersampling of the majority class. Let's add, after the oversampling, a random undersampling step in our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "valuable-rabbit",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T12:38:36.113036Z",
     "start_time": "2022-01-10T12:26:33.642841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'over__sampling_strategy': 0.4, 'under__sampling_strategy': 0.4}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit time (s)</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>CV ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smote_under_pipe</th>\n",
       "      <td>16.557154</td>\n",
       "      <td>0.731421</td>\n",
       "      <td>0.709923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fit time (s)   ROC AUC  CV ROC AUC\n",
       "smote_under_pipe     16.557154  0.731421    0.709923"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "# Iclude an undersampling step into the pipeline\n",
    "smote_pipe = imbpipe.Pipeline([\n",
    "             ('cleaning', full_pipeline),\n",
    "             ('over', SMOTE(n_jobs=1, random_state=42)),  \n",
    "             ('under', RandomUnderSampler(random_state=42)),\n",
    "             ('model', lgbm)\n",
    "             ])\n",
    "\n",
    "# Fine-tune the sampling strategy of both\n",
    "# under and over-sampling\n",
    "param_grid = [{'over__sampling_strategy': [.1],\n",
    "               'under__sampling_strategy': np.linspace(.1, .5, 5)\n",
    "             },\n",
    "             {'over__sampling_strategy': [.2],\n",
    "              'under__sampling_strategy': np.linspace(.2, .6, 5)\n",
    "             },\n",
    "             {'over__sampling_strategy': [.3],\n",
    "              'under__sampling_strategy': np.linspace(.3, .7, 5)\n",
    "             },\n",
    "             {'over__sampling_strategy': [.4],\n",
    "              'under__sampling_strategy': np.linspace(.4, .8, 5)\n",
    "             },\n",
    "             {'over__sampling_strategy': [.5],\n",
    "              'under__sampling_strategy': np.linspace(.5, .9, 5)\n",
    "             }]\n",
    "              \n",
    "grid_search = GridSearchCV(smote_pipe, param_grid,\n",
    "                                  cv=cv, n_jobs=-1)\n",
    "grid_search.fit(X, y_train)\n",
    "print()\n",
    "smote_pipe = grid_search.best_estimator_\n",
    "print(grid_search.best_params_)\n",
    "              \n",
    "# Display the model results\n",
    "t0 = time.time()\n",
    "smote_pipe.fit(X, y_train)\n",
    "t1 = time.time()\n",
    "y_pred = smote_pipe.predict_proba(X)\n",
    "y_pred_cv = cross_val_predict(smote_pipe, X, y_train, cv=cv, n_jobs=-1,\n",
    "                              method=\"predict_proba\")\n",
    "\n",
    "time_fit = t1 - t0\n",
    "score = roc_auc_score(y_train, y_pred[:, 1])\n",
    "cv_score = roc_auc_score(y_train, y_pred_cv[:, 1])\n",
    "\n",
    "pd.DataFrame(np.array([time_fit, score, cv_score.mean()]).reshape(1, -1),\n",
    "             columns=['fit time (s)', 'ROC AUC', 'CV ROC AUC'],\n",
    "\n",
    "             index=[\"smote_under_pipe\"])              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-maine",
   "metadata": {},
   "source": [
    "## Improve the promising models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-centre",
   "metadata": {},
   "source": [
    "### Test the asumptions made for data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-pilot",
   "metadata": {},
   "source": [
    "To test these asumptions, we will use a grid search with the LightGBM algorithm, given that it is the fastest to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "configured-alexandria",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T12:43:28.148330Z",
     "start_time": "2022-01-10T12:42:36.860483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cleaning__cat__filter__kw_args': {'na_threshold': 0.2}, 'cleaning__cat__imputer__kw_args': {'na_threshold': 0.2}, 'cleaning__dense__filter__kw_args': {'na_threshold': 0.2}, 'cleaning__ordinal__filter__kw_args': {'na_threshold': 0.2}, 'cleaning__sparse__filter__kw_args': {'na_threshold': 0.2}}\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "import imblearn.pipeline as imbpipe\n",
    "\n",
    "pipeline = imbpipe.Pipeline([\n",
    "           ('cleaning', full_pipeline),\n",
    "           #('over', SMOTE(n_jobs=1, random_state=42)),  \n",
    "           #('under', RandomUnderSampler(random_state=42)),\n",
    "          ('model', lgbm)\n",
    "          ])\n",
    "\n",
    "# get the best threshold to filter features\n",
    "param_grid = [{'cleaning__cat__filter__kw_args': [{'na_threshold':.2}],\n",
    "               'cleaning__cat__imputer__kw_args':[{'na_threshold':.2}],\n",
    "               'cleaning__ordinal__filter__kw_args': [{'na_threshold':.2}],\n",
    "               'cleaning__sparse__filter__kw_args': [{'na_threshold':.2}],\n",
    "               'cleaning__dense__filter__kw_args': [{'na_threshold':.2}]\n",
    "              },\n",
    "              {'cleaning__cat__filter__kw_args': [{'na_threshold':.3}],\n",
    "               'cleaning__cat__imputer__kw_args':[{'na_threshold':.3}],\n",
    "               'cleaning__ordinal__filter__kw_args': [{'na_threshold':.3}],\n",
    "               'cleaning__sparse__filter__kw_args': [{'na_threshold':.3}],\n",
    "               'cleaning__dense__filter__kw_args': [{'na_threshold':.3}]\n",
    "              },\n",
    "              {'cleaning__cat__filter__kw_args': [{'na_threshold':.4}],\n",
    "               'cleaning__cat__imputer__kw_args':[{'na_threshold':.4}],\n",
    "               'cleaning__ordinal__filter__kw_args': [{'na_threshold':.4}],\n",
    "               'cleaning__sparse__filter__kw_args': [{'na_threshold':.4}],\n",
    "               'cleaning__dense__filter__kw_args': [{'na_threshold':.4}]\n",
    "              },\n",
    "              {'cleaning__cat__filter__kw_args': [{'na_threshold':.5}],\n",
    "               'cleaning__cat__imputer__kw_args':[{'na_threshold':.5}],\n",
    "               'cleaning__ordinal__filter__kw_args': [{'na_threshold':.5}],\n",
    "               'cleaning__sparse__filter__kw_args': [{'na_threshold':.5}],\n",
    "               'cleaning__dense__filter__kw_args': [{'na_threshold':.5}]\n",
    "              }]\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid,\n",
    "                           scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "grid_search.fit(X, y_train)\n",
    "pipeline = grid_search.best_estimator_\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-module",
   "metadata": {},
   "source": [
    "The results are better if we drop all features with at least 20% of no values. Let's change the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "irish-puppy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T12:44:27.176085Z",
     "start_time": "2022-01-10T12:43:28.150261Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cleaning__dense__domain_adder__kw_args': {'add_domain_features': True, 'names': ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'CNT_FAM_MEMBERS', 'HOUR_APPR_PROCESS_START', 'DAYS_LAST_PHONE_CHANGE', 'AMT_REQ_CREDIT_BUREAU_YEAR', 'DAYS_EMPLOYED_ANOM']}, 'cleaning__dense__skew_transformer__kw_args': {'log': False}}\n"
     ]
    }
   ],
   "source": [
    "na_threshold = pipeline.get_params()['cleaning__cat__filter__kw_args']['na_threshold']\n",
    "filtered_dense_att = list(drop_na_att(X[dense_att], na_threshold)) + ['DAYS_EMPLOYED_ANOM']\n",
    "\n",
    "# Check all feature engineering steps\n",
    "param_grid = [{'cleaning__dense__domain_adder__kw_args': [{'add_domain_features': True,\n",
    "                                                           'names': filtered_dense_att},\n",
    "                                                          {'add_domain_features': False,\n",
    "                                                           'names': filtered_dense_att}],\n",
    "               'cleaning__dense__skew_transformer__kw_args': [{'log': True},\n",
    "                                                              {'log': False}]\n",
    "              }]\n",
    "grid_search = GridSearchCV(pipeline, param_grid,\n",
    "                           scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "grid_search.fit(X, y_train)\n",
    "pipeline = grid_search.best_estimator_\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-candle",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-monte",
   "metadata": {},
   "source": [
    "Our objective is not to get the best model, but a good one with results easy to explain. Our dataset has 171 features, it is too much to hope understanding the models results clearly, we must reduce them. In most cases, reducing the number of features leads to poorer results.  \n",
    "Let's find a good features number to keep. By good we mean a number which massively decrease the features with a minimum impact on the results. The features will be selected with the `feature_importances` attibute of the Random Forest algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "consistent-comment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T13:00:36.348995Z",
     "start_time": "2022-01-10T12:58:25.260130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166 features: 0.714\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# ROC AUC score with all features\n",
    "score = cross_val_score(lgbm, X_train, y_train, scoring='roc_auc',\n",
    "                        cv=cv, n_jobs=-1)\n",
    "print(f\"{X_smote.shape[1]} features: {score.mean():.3}\")\n",
    "# Select the top 100 features\n",
    "sfm_scores = []\n",
    "sfm = SelectFromModel(lgbm, threshold=-np.inf, max_features=100)\n",
    "X_sfm = sfm.fit_transform(X_train, y_train)\n",
    "score = cross_val_score(lgbm, X_sfm, y_train,\n",
    "                            scoring='roc_auc',\n",
    "                            cv=cv, n_jobs=-1)\n",
    "sfm_scores.append(score.mean())\n",
    "# Test different numbers of features from 50 to 100\n",
    "for i in range(95, 5, -5):\n",
    "    sfm = SelectFromModel(lgbm, threshold=-np.inf, max_features=i)\n",
    "    X_sfm = sfm.fit_transform(X_sfm, y_train)\n",
    "    score = cross_val_score(lgbm, X_sfm, y_train,\n",
    "                            scoring='roc_auc',\n",
    "                            cv=cv, n_jobs=-1)\n",
    "    sfm_scores.append(score.mean())\n",
    "# Plot the results\n",
    "plt.plot(np.arange(10, 105, 5), sfm_scores[::-1])\n",
    "plt.xlabel(\"N features\")\n",
    "plt.ylabel(\"ROC AUC\") \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-footage",
   "metadata": {},
   "source": [
    "We may notice that the model performance is not impacted until 45 features. We will keep then only 45 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "increasing-scheduling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T13:03:07.651120Z",
     "start_time": "2022-01-10T13:03:07.648621Z"
    }
   },
   "outputs": [],
   "source": [
    "selector = SelectFromModel(lgbm, threshold=-np.inf, max_features=45)\n",
    "\n",
    "pipeline = imbpipe.Pipeline([\n",
    "           ('cleaning', full_pipeline),\n",
    "           #('over', SMOTE(n_jobs=1, random_state=42)),  \n",
    "           #('under', RandomUnderSampler(random_state=42)),\n",
    "           ('feature_selection', selector),\n",
    "           ('model', lgbm)\n",
    "           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "first-belarus",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T13:04:40.533240Z",
     "start_time": "2022-01-10T13:04:10.064945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit time (s)</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>CV ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.577048</td>\n",
       "      <td>0.753885</td>\n",
       "      <td>0.713615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit time (s)   ROC AUC  CV ROC AUC\n",
       "0      8.577048  0.753885    0.713615"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the model results\n",
    "t0 = time.time()\n",
    "pipeline.fit(X, y_train)\n",
    "t1 = time.time()\n",
    "y_pred = pipeline.predict_proba(X)\n",
    "y_pred_cv = cross_val_predict(pipeline, X, y_train, cv=cv, n_jobs=-1,\n",
    "                              method=\"predict_proba\")\n",
    "\n",
    "time_fit = t1 - t0\n",
    "score = roc_auc_score(y_train, y_pred[:, 1])\n",
    "cv_score = roc_auc_score(y_train, y_pred_cv[:, 1])\n",
    "\n",
    "pd.DataFrame(np.array([time_fit, score, cv_score.mean()]).reshape(1, -1),\n",
    "             columns=['fit time (s)', 'ROC AUC', 'CV ROC AUC'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-mixture",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:04:22.204630Z",
     "start_time": "2022-01-06T21:58:14.272Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "rfe = RFE(lgbm, n_features_to_select=40, step=5, verbose=1)\n",
    "X_40 = rfe.fit_transform(X_train, y_train)\n",
    "mask_40 = rfe.support_\n",
    "forest.fit(X_40, y_smote)\n",
    "print(f\"{X_40.shape[1]} features: {forest.oob_score_:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-colorado",
   "metadata": {},
   "source": [
    "## Fine-Tune the hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-front",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-lunch",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T22:04:22.212055Z",
     "start_time": "2022-01-06T21:58:16.931Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "cv = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "forest = RandomForestClassifier(random_state=42,\n",
    "                                bootstrap=True,\n",
    "                                n_jobs=-1)\n",
    "param_grid = {'max_features': np.arange(4, 13)}\n",
    "\n",
    "grid_search = HalvingGridSearchCV(forest, param_grid, cv=cv,\n",
    "                                  n_jobs=-1, verbose=1,\n",
    "                                  random_state=42)\n",
    "grid_search.fit(X_40, y_smote)\n",
    "forest = grid_search.best_estimator_\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-encounter",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-naples",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T21:04:55.553560Z",
     "start_time": "2022-01-06T20:16:16.614Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "cv = StratifiedKFold(3, shuffle=True, random_state=42)\n",
    "xgb = XGBClassifier(n_estimators=100,\n",
    "                    random_state=42)\n",
    "                                                              \n",
    "param_grid = [{'learning_rate': [0.02, 0.05, 0.1, 0.2],\n",
    "              'max_depth': [6, 8, 10, 12, 15, 20]}]\n",
    "grid_search = HalvingGridSearchCV(xgb, param_grid, factor=5,\n",
    "                                  cv=cv, verbose=1,\n",
    "                                  n_jobs=-1, random_state=42)\n",
    "grid_search.fit(X_40, y_smote, eval_metric='logloss')\n",
    "xgb = grid_search.best_estimator_\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-blend",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T21:04:55.554442Z",
     "start_time": "2022-01-06T20:16:18.936Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data set into a train and test set\n",
    "# to use early stopping\n",
    "X_gb_train, X_gb_test, y_gb_train, y_gb_test = train_test_split(X_40, y_smote, random_state=42)\n",
    "\n",
    "xgb.fit(X_gb_train, y_gb_train,\n",
    "        eval_set=[(X_gb_test, y_gb_test)],\n",
    "        eval_metric='logloss',\n",
    "        early_stopping_rounds=3,\n",
    "        verbose=False)\n",
    "xgb.n_estimators = xgb.best_iteration + 1\n",
    "print(\"The best iteration is {}\".format(xgb.n_estimators))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-notification",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-acrobat",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T21:04:55.555265Z",
     "start_time": "2022-01-06T20:16:23.118Z"
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm = LGBMClassifier(n_estimators=100,\n",
    "                      random_state=42)\n",
    "\n",
    "param_grid = {'learning_rate': [0.02, 0.05, 0.1, 0.2, 0.3],\n",
    "              'max_depth': [6, 8, 10, 12, 15, 20]}\n",
    "grid_search = GridSearchCV(lgbm, param_grid, cv=cv,\n",
    "                           verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_40, y_smote)\n",
    "lgbm = grid_search.best_estimator_\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-marker",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T21:04:55.556162Z",
     "start_time": "2022-01-06T20:16:24.414Z"
    }
   },
   "outputs": [],
   "source": [
    "lgbm.fit(X_gb_train, y_gb_train,\n",
    "         eval_set=[(X_gb_test, y_gb_test)],\n",
    "         early_stopping_rounds=3,\n",
    "         verbose=False)\n",
    "lgbm.n_estimators = lgbm.best_iteration_\n",
    "print(\"The best iteration is {}\".format(lgbm.n_estimators))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-highland",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-version",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T18:41:40.655690Z",
     "start_time": "2022-01-06T18:41:04.485Z"
    }
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "catboost = CatBoostClassifier(n_estimators=100,\n",
    "                              random_state=42)\n",
    "\n",
    "param_grid = {'learning_rate': [0.02, 0.05, 0.1, 0.2],\n",
    "              'max_depth': [6, 8, 10, 12, 15]}\n",
    "grid_search = HalvingGridSearchCV(catboost, param_grid, factor=5,\n",
    "                                  cv=cv, verbose=1,\n",
    "                                  n_jobs=-1, random_state=42)\n",
    "grid_search.fit(X_40, y_smote, verbose=False)\n",
    "catboost = grid_search.best_estimator_\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-horse",
   "metadata": {},
   "source": [
    "### Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-discretion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T18:41:40.656513Z",
     "start_time": "2022-01-06T18:41:04.487Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display the results in a DataFrame\n",
    "models = {'XGBoost Classifier': xgb,\n",
    "          'LightGBM Classifier': lgbm,\n",
    "          'CatBoost Classifier': catboost,\n",
    "          'Random Forest Classifier': forest}\n",
    "compare_models(X_40, y_smote, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-liverpool",
   "metadata": {},
   "source": [
    "Fine tuning hyperparameters leads to a slight improvement of results.  \n",
    "The best model is **Random Forest**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-jacksonville",
   "metadata": {},
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-breach",
   "metadata": {},
   "source": [
    "Let's increase the number of tree of the Random Forest to 500 to increase the preformance of the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-wings",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T18:41:40.657381Z",
     "start_time": "2022-01-06T18:41:04.489Z"
    }
   },
   "outputs": [],
   "source": [
    "forest.n_estimators = 500\n",
    "print(forest.get_params())\n",
    "compare_models(X_40, y_smote, {'Random Forest Classifier': forest})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-summary",
   "metadata": {},
   "source": [
    "## Analyse feature importance with SHAP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
