{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "blessed-arnold",
   "metadata": {},
   "source": [
    "# Project 7: Implement a scoring model.\n",
    "\n",
    "*Pierre-Eloi Ragetly*\n",
    "\n",
    "This project is part of the Data Scientist path proposed by OpenClassrooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "described-blind",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T17:10:20.035429Z",
     "start_time": "2021-09-21T17:10:19.186680Z"
    }
   },
   "outputs": [],
   "source": [
    "# File system management\n",
    "import os\n",
    "\n",
    "# Get execution time to compare models\n",
    "import time\n",
    "\n",
    "# Import numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams.update({'axes.edgecolor': 'white',\n",
    "                     'axes.facecolor': 'white',\n",
    "                     'axes.linewidth': 2.0,\n",
    "                     'figure.facecolor': 'white'})\n",
    "\n",
    "# Where to save the figures\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    folder_path = os.path.join(\"charts\")\n",
    "    if not os.path.isdir(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    path = os.path.join(\"charts\", fig_id + \".png\")\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)\n",
    "\n",
    "# Get all functions required to prepare data\n",
    "from functions.data_preparation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-chair",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Prepare-the-data\" data-toc-modified-id=\"Prepare-the-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Prepare the data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Read-in-data\" data-toc-modified-id=\"Read-in-data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Read in data</a></span></li><li><span><a href=\"#Transform-data\" data-toc-modified-id=\"Transform-data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Transform data</a></span></li></ul></li><li><span><a href=\"#Shortlist-Promising-Models\" data-toc-modified-id=\"Shortlist-Promising-Models-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Shortlist Promising Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Select-a-Performance-Measure\" data-toc-modified-id=\"Select-a-Performance-Measure-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Select a Performance Measure</a></span></li><li><span><a href=\"#Establish-a-performance-baseline-with-a-dummy-classifier\" data-toc-modified-id=\"Establish-a-performance-baseline-with-a-dummy-classifier-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Establish a performance baseline with a dummy classifier</a></span></li><li><span><a href=\"#Train-quick-and-dirty-models-and-compare-their-performance\" data-toc-modified-id=\"Train-quick-and-dirty-models-and-compare-their-performance-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Train quick and dirty models and compare their performance</a></span></li></ul></li><li><span><a href=\"#Improve-the-models-selected\" data-toc-modified-id=\"Improve-the-models-selected-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Improve the models selected</a></span><ul class=\"toc-item\"><li><span><a href=\"#Use-as-much-data-as-possible-by-merging-all-tables\" data-toc-modified-id=\"Use-as-much-data-as-possible-by-merging-all-tables-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Use as much data as possible by merging all tables</a></span></li><li><span><a href=\"#Data-augmentation-with-SMOTE\" data-toc-modified-id=\"Data-augmentation-with-SMOTE-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Data augmentation with SMOTE</a></span></li><li><span><a href=\"#Fine-Tune-the-hyperparameters-using-cross-validation\" data-toc-modified-id=\"Fine-Tune-the-hyperparameters-using-cross-validation-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Fine-Tune the hyperparameters using cross-validation</a></span></li><li><span><a href=\"#Try-ensemble-methods-and-select-the-final-model\" data-toc-modified-id=\"Try-ensemble-methods-and-select-the-final-model-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Try ensemble methods and select the final model</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-designation",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-removal",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "permanent-vinyl",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T17:10:49.392611Z",
     "start_time": "2021-09-21T17:10:20.036950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) application_test.csv\n",
      "2) application_train.csv\n",
      "3) bureau.csv\n",
      "4) bureau_balance.csv\n",
      "5) credit_card_balance.csv\n",
      "6) HomeCredit_columns_description.csv\n",
      "7) installments_payments.csv\n",
      "8) POS_CASH_balance.csv\n",
      "9) previous_application.csv\n",
      "10) sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "list_files = sorted(os.listdir(\"data/\"), key=str.lower)\n",
    "for i, file in enumerate(list_files):\n",
    "    print(\"{}) {}\".format(i+1, file))\n",
    "\n",
    "app_test = pd.read_csv(\"data/\" + list_files[0])\n",
    "app_train = pd.read_csv(\"data/\" + list_files[1])\n",
    "bureau =  pd.read_csv(\"data/\" + list_files[2])\n",
    "b_b = pd.read_csv(\"data/\" + list_files[3])\n",
    "cc_balance = pd.read_csv(\"data/\" + list_files[4])\n",
    "ins_payments = pd.read_csv(\"data/\" + list_files[6])\n",
    "pos_cash = pd.read_csv(\"data/\" + list_files[7])\n",
    "prev_app = pd.read_csv(\"data/\" + list_files[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-portable",
   "metadata": {},
   "source": [
    "### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "finished-lighter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T17:10:49.400181Z",
     "start_time": "2021-09-21T17:10:49.394718Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "emerging-agenda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T17:10:50.886874Z",
     "start_time": "2021-09-21T17:10:49.402061Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop the target and the ID of input data\n",
    "X = app_train.drop(['SK_ID_CURR', 'TARGET'], axis=1)\n",
    "\n",
    "# Get the categorical attributes\n",
    "cat_att = list(X.select_dtypes('object'))\n",
    "\n",
    "# Get the values to fill missing values\n",
    "values = drop_na_att(X[cat_att]).value_counts().index[0]\n",
    "\n",
    "# Get the numerical attributes\n",
    "num_att = list(X.select_dtypes(['int', 'float']))\n",
    "ord_att = list(X[num_att].loc[:, X[num_att].nunique()<6])\n",
    "sparse_att = [c for c in num_att\n",
    "              if c not in ord_att\n",
    "              and (X[c]==0).sum() > 0.5*len(X)]\n",
    "dense_att = [c for c in num_att\n",
    "             if c not in ord_att\n",
    "             and c not in sparse_att]\n",
    "filtered_dense_att = list(drop_na_att(X[dense_att])) + ['DAYS_EMPLOYED_ANOM']\n",
    "\n",
    "# Create a pipeline with an encoder\n",
    "# drop the first category in each feature with two categories (drop='if_binary')\n",
    "cat_pipeline = Pipeline([\n",
    "               ('filter', FunctionTransformer(drop_na_att)),               \n",
    "               ('imputer', FunctionTransformer(impute_cat_att,\n",
    "                                               kw_args={'values': values})),\n",
    "               ('encoder', OneHotEncoder(drop='if_binary')),\n",
    "               ])\n",
    "\n",
    "# Pipeline to prepare numerical ordinal features\n",
    "ord_pipeline = Pipeline([\n",
    "               ('filter', FunctionTransformer(drop_na_att)),\n",
    "               ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "               ])\n",
    "\n",
    "# Pipeline to prepare sparse features with at least 6 distinct values\n",
    "sparse_pipeline = Pipeline([\n",
    "                  ('filter', FunctionTransformer(drop_na_att)),\n",
    "                  ('cleaner', FunctionTransformer(fix_sparse_anomalies)),\n",
    "                  ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                  ('scaler', MaxAbsScaler())\n",
    "                  ])\n",
    "\n",
    "# Pipeline to prepare dense features with at least 6 distinct values\n",
    "dense_pipeline = Pipeline([\n",
    "                 ('filter', FunctionTransformer(drop_na_att)),\n",
    "                 ('cleaner', FunctionTransformer(fix_dense_anomalies)),\n",
    "                 ('imputer', SimpleImputer()),\n",
    "                 ('poly_adder', FunctionTransformer(add_polynomial_att,\n",
    "                                                    kw_args={'names': filtered_dense_att})),\n",
    "                 ('domain_adder', FunctionTransformer(add_domain_att)),\n",
    "                 ('skew_transformer', FunctionTransformer(tr_skew_att)),\n",
    "                 ('scaler', StandardScaler())\n",
    "                 ])\n",
    "\n",
    "# Pipeline to prepare all data\n",
    "full_pipeline = ColumnTransformer([\n",
    "                ('cat', cat_pipeline, cat_att),\n",
    "                ('ordinal', ord_pipeline, ord_att),\n",
    "                ('sparse', sparse_pipeline, sparse_att),\n",
    "                ('dense', dense_pipeline, dense_att),\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "lesser-amino",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T13:29:07.824743Z",
     "start_time": "2021-09-22T13:29:04.028549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_CONTRACT_TYPE_Revolving loans</th>\n",
       "      <th>CODE_GENDER_F</th>\n",
       "      <th>CODE_GENDER_M</th>\n",
       "      <th>CODE_GENDER_XNA</th>\n",
       "      <th>FLAG_OWN_CAR_Y</th>\n",
       "      <th>FLAG_OWN_REALTY_Y</th>\n",
       "      <th>NAME_TYPE_SUITE_Children</th>\n",
       "      <th>NAME_TYPE_SUITE_Family</th>\n",
       "      <th>NAME_TYPE_SUITE_Group of people</th>\n",
       "      <th>NAME_TYPE_SUITE_Other_A</th>\n",
       "      <th>...</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <th>DAYS_EMPLOYED_ANOM</th>\n",
       "      <th>EXT_SOURCE_2^2</th>\n",
       "      <th>EXT_SOURCE_2 EXT_SOURCE_3</th>\n",
       "      <th>EXT_SOURCE_3^2</th>\n",
       "      <th>DAYS_EMPLOYED_PERC</th>\n",
       "      <th>CREDIT_INCOME_PERC</th>\n",
       "      <th>INCOME_PER_PERSON</th>\n",
       "      <th>ANNUITY_INCOME_PERC</th>\n",
       "      <th>CREDIT_TERM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.176655e-01</td>\n",
       "      <td>-0.468635</td>\n",
       "      <td>-1.350227</td>\n",
       "      <td>-1.632233</td>\n",
       "      <td>-1.608672</td>\n",
       "      <td>-0.685451</td>\n",
       "      <td>-0.755852</td>\n",
       "      <td>1.548683</td>\n",
       "      <td>-0.629679</td>\n",
       "      <td>0.326909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.092866e+00</td>\n",
       "      <td>-0.468635</td>\n",
       "      <td>0.501725</td>\n",
       "      <td>0.369212</td>\n",
       "      <td>-0.180027</td>\n",
       "      <td>-0.652211</td>\n",
       "      <td>0.567970</td>\n",
       "      <td>0.912393</td>\n",
       "      <td>-0.510993</td>\n",
       "      <td>-1.178242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.092866e+00</td>\n",
       "      <td>-0.468635</td>\n",
       "      <td>0.046658</td>\n",
       "      <td>0.993350</td>\n",
       "      <td>1.424589</td>\n",
       "      <td>-1.222743</td>\n",
       "      <td>-0.761159</td>\n",
       "      <td>-0.175347</td>\n",
       "      <td>-0.888140</td>\n",
       "      <td>-0.155923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.831603e-16</td>\n",
       "      <td>-0.468635</td>\n",
       "      <td>0.710676</td>\n",
       "      <td>0.471723</td>\n",
       "      <td>-0.180027</td>\n",
       "      <td>0.151233</td>\n",
       "      <td>-0.558658</td>\n",
       "      <td>-0.175347</td>\n",
       "      <td>0.463536</td>\n",
       "      <td>1.830833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.092866e+00</td>\n",
       "      <td>-0.468635</td>\n",
       "      <td>-1.146322</td>\n",
       "      <td>-0.719692</td>\n",
       "      <td>-0.180027</td>\n",
       "      <td>0.086094</td>\n",
       "      <td>0.359119</td>\n",
       "      <td>0.747053</td>\n",
       "      <td>0.028661</td>\n",
       "      <td>-0.490159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NAME_CONTRACT_TYPE_Revolving loans  CODE_GENDER_F  CODE_GENDER_M  \\\n",
       "0                                 0.0            0.0            1.0   \n",
       "1                                 0.0            1.0            0.0   \n",
       "2                                 1.0            0.0            1.0   \n",
       "3                                 0.0            1.0            0.0   \n",
       "4                                 0.0            0.0            1.0   \n",
       "\n",
       "   CODE_GENDER_XNA  FLAG_OWN_CAR_Y  FLAG_OWN_REALTY_Y  \\\n",
       "0              0.0             0.0                1.0   \n",
       "1              0.0             0.0                0.0   \n",
       "2              0.0             1.0                1.0   \n",
       "3              0.0             0.0                1.0   \n",
       "4              0.0             0.0                1.0   \n",
       "\n",
       "   NAME_TYPE_SUITE_Children  NAME_TYPE_SUITE_Family  \\\n",
       "0                       0.0                     0.0   \n",
       "1                       0.0                     1.0   \n",
       "2                       0.0                     0.0   \n",
       "3                       0.0                     0.0   \n",
       "4                       0.0                     0.0   \n",
       "\n",
       "   NAME_TYPE_SUITE_Group of people  NAME_TYPE_SUITE_Other_A  ...  \\\n",
       "0                              0.0                      0.0  ...   \n",
       "1                              0.0                      0.0  ...   \n",
       "2                              0.0                      0.0  ...   \n",
       "3                              0.0                      0.0  ...   \n",
       "4                              0.0                      0.0  ...   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_YEAR  DAYS_EMPLOYED_ANOM  EXT_SOURCE_2^2  \\\n",
       "0               -5.176655e-01           -0.468635       -1.350227   \n",
       "1               -1.092866e+00           -0.468635        0.501725   \n",
       "2               -1.092866e+00           -0.468635        0.046658   \n",
       "3               -3.831603e-16           -0.468635        0.710676   \n",
       "4               -1.092866e+00           -0.468635       -1.146322   \n",
       "\n",
       "   EXT_SOURCE_2 EXT_SOURCE_3  EXT_SOURCE_3^2  DAYS_EMPLOYED_PERC  \\\n",
       "0                  -1.632233       -1.608672           -0.685451   \n",
       "1                   0.369212       -0.180027           -0.652211   \n",
       "2                   0.993350        1.424589           -1.222743   \n",
       "3                   0.471723       -0.180027            0.151233   \n",
       "4                  -0.719692       -0.180027            0.086094   \n",
       "\n",
       "   CREDIT_INCOME_PERC  INCOME_PER_PERSON  ANNUITY_INCOME_PERC  CREDIT_TERM  \n",
       "0           -0.755852           1.548683            -0.629679     0.326909  \n",
       "1            0.567970           0.912393            -0.510993    -1.178242  \n",
       "2           -0.761159          -0.175347            -0.888140    -0.155923  \n",
       "3           -0.558658          -0.175347             0.463536     1.830833  \n",
       "4            0.359119           0.747053             0.028661    -0.490159  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data\n",
    "y_train = app_train['TARGET']\n",
    "X_train = full_pipeline.fit_transform(X)\n",
    "\n",
    "# Get the name of onehot encoded features\n",
    "onehot_att = list(drop_na_att(X[cat_att]))\n",
    "encoder = OneHotEncoder(drop='if_binary')\n",
    "encoder.fit(impute_cat_att(X[onehot_att], values=values))\n",
    "onehot_att = list(encoder.get_feature_names(onehot_att))\n",
    "# Get the name of polynomial attributes\n",
    "poly_att = ['EXT_SOURCE_2', 'EXT_SOURCE_3']\n",
    "poly_transformer = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly_transformer.fit(X[poly_att].fillna(X[poly_att].mean()))\n",
    "n = len(poly_att)\n",
    "poly_att = poly_transformer.get_feature_names(input_features=poly_att)[n:]\n",
    "# Get the name of domain attributes\n",
    "domain_att = ['DAYS_EMPLOYED_PERC', 'CREDIT_INCOME_PERC', 'INCOME_PER_PERSON',\n",
    "              'ANNUITY_INCOME_PERC', 'CREDIT_TERM']\n",
    "# Get the name of all attributes\n",
    "extra_att = ['DAYS_EMPLOYED_ANOM'] + poly_att + domain_att\n",
    "final_att = onehot_att + list(drop_na_att(X[num_att])) + extra_att\n",
    "\n",
    "df = pd.DataFrame(X_train, columns=final_att)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-international",
   "metadata": {},
   "source": [
    "## Shortlist Promising Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-sailing",
   "metadata": {},
   "source": [
    "### Select a Performance Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "furnished-accent",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T08:14:27.745958Z",
     "start_time": "2021-09-22T08:14:27.741917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of the positive class: 8.1%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percentage of the positive class: \\\n",
    "{app_train['TARGET'].value_counts()[1]/len(app_train):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-tenant",
   "metadata": {},
   "source": [
    "Though *accuracy* is generally the first performance used for binary classification, it is seldom the best choice when we are dealing with *skewed dataset*, like the one we have.  \n",
    "To prove it, let's take a very dumb classifier that just classifies every instance in the *negative* class (meaning the majority class). We would get an accuracy of $92\\%$, not bad for such dumb classifier! Thus, no matter the model used, the accuracy will be high. It will be difficult to know if our model really learn something, whether it has skill on the dataset.\n",
    "\n",
    "There are much better way to evaluate the performance of a classifier, such as the *AUC* (Area under the curve) or the *F1* Score. The latter is the *harmonic mean* of *Precision* and *Recall*:\n",
    "\n",
    "$\\displaystyle 2 \\times \\frac {precision \\times recall}{precision + recall}$\n",
    "\n",
    "Many people compute the AUC on the ROC (Receiver operating characteristic) curve. However, when the positive class is rare (like it is the case here) the ROC curves may be optimistic. For that reason we will prefer to use the Precision_Recall curve.\n",
    "\n",
    "There is another reason to take the Precision_Recall curve. Let's go back to the objectif:  \n",
    "**Predict if a new client will be in default or not.**\n",
    "\n",
    "It will cost much more money for the bank to grant a loan to a person that will be not able to repay it, than the opposite, refuse to approve a loan for someone who could pay it back. Meaning we care more about *False Negative* than *False Positive*, in other words, whe prefer having a high *Recall* than a high *Precision*. The advantage of the Precision_Recall plot, is to provide an easy tool to select the good threshold for the decision function. By good, we mean a precision/recall trade-off aligned with the objective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-diversity",
   "metadata": {},
   "source": [
    "### Establish a performance baseline with a dummy classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-intersection",
   "metadata": {},
   "source": [
    "A performance baseline provides a minimum score above which a model is considered to have skill on the dataset. It provides a line by which all other algorithms can be compared. A baseline can be established using a naive classifier, such as predicting the most frequent class label for all examples in the dataset.\n",
    "\n",
    "Each metric requires the careful choice of a specific naive classification strategy that achieves the appropriate \"*no skill*\" performance. A no-skill model has a PR AUC (Precision-Recall area under the curve) that matches the base rate of the positive class, e.g. 8.1%. This can be achieved by predicting class labels randomly, while respecting the training set's class distribution.  \n",
    "We will use the \"*stratified*\" strategy of the sklearn class DummyClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "composed-needle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T13:45:07.298184Z",
     "start_time": "2021-09-22T13:45:07.262777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(strategy='stratified')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Train a dummy classifier\n",
    "dummy_clf = DummyClassifier(strategy='stratified')\n",
    "dummy_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adult-gravity",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T13:44:12.240580Z",
     "start_time": "2021-09-22T13:44:12.237515Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "def pr_auc(y_true, probas_pred):\n",
    "    \"\"\"Calculate precision-recall area under curve.\n",
    "    -----------\n",
    "    Parameters:\n",
    "    y_true: ndarray of shape (n_samples,)\n",
    "        True binary labels.\n",
    "    probas_pred: ndarray of shape (n_samples,)\n",
    "        Estimated probabilities or output of a decision function.\n",
    "    \"\"\"\n",
    "    # calculate precision-recall curve\n",
    "    p, r, t = precision_recall_curve(y_true, probas_pred)\n",
    "    # calculate area under curve\n",
    "    return auc(r, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "quarterly-specific",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T13:51:27.462264Z",
     "start_time": "2021-09-22T13:51:26.609432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC = 0.12\n",
      "F1 score = 0.08\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Get clean prediction\n",
    "cv = StratifiedKFold(5, random_state=42)\n",
    "y_train_pred = cross_val_predict(dummy_clf, X_train, y_train, cv=cv, n_jobs=-1)\n",
    "\n",
    "# Compute the PR AUC\n",
    "dummy_pr_auc = pr_auc(y_train, y_train_pred)\n",
    "print(f\"PR AUC = {dummy_pr_auc:.2f}\")\n",
    "\n",
    "# Compute the F1 score\n",
    "dummy_f1_score = f1_score(y_train, y_train_pred)\n",
    "print(f\"F1 score = {dummy_f1_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-barbados",
   "metadata": {},
   "source": [
    "### Train quick and dirty models and compare their performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-crazy",
   "metadata": {},
   "source": [
    "## Select a final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-raising",
   "metadata": {},
   "source": [
    "### Use as much data as possible by merging all tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-architect",
   "metadata": {},
   "source": [
    "### Data augmentation with SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-moore",
   "metadata": {},
   "source": [
    "### Fine-Tune the hyperparameters using cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-summary",
   "metadata": {},
   "source": [
    "## Analyse feature importance with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-editor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
